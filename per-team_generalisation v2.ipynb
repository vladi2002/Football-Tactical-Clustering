{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153353c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.25.2\n",
      "Uninstalling numpy-1.25.2:\n",
      "  Successfully uninstalled numpy-1.25.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall numpy -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939e3f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy>=2.0.0\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.2.6 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy>=2.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b0db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9193b47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.data import Data\n",
    "print(\"✅ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b7b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]\n",
      "NumPy: 2.2.6\n",
      "SciPy: 1.15.3\n",
      "PyTorch: 2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "import numpy, scipy, torch\n",
    "print(\"NumPy:\", numpy.__version__)\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"PyTorch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b321ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy>=1.14.1\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting numpy<2.5,>=1.23.5 (from scipy>=1.14.1)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/41.3 MB 4.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.6/41.3 MB 6.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.5/41.3 MB 7.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.3/41.3 MB 7.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.9/41.3 MB 7.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.4/41.3 MB 7.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 11.3/41.3 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.1/41.3 MB 7.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.7/41.3 MB 7.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 16.5/41.3 MB 7.9 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 18.1/41.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 20.2/41.3 MB 8.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.8/41.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 23.3/41.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.9/41.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 26.7/41.3 MB 7.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 28.6/41.3 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 30.1/41.3 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.0/41.3 MB 8.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.8/41.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.4/41.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 37.0/41.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 39.1/41.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 7.8 MB/s  0:00:05\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy, scipy\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.1.2\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Uninstalling numpy-2.1.2:\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "  Attempting uninstall: scipy\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Found existing installation: scipy 1.11.4\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "    Uninstalling scipy-1.11.4:\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "      Successfully uninstalled scipy-1.11.4\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   ---------------------------------------- 2/2 [scipy]\n",
      "\n",
      "Successfully installed numpy-2.2.6 scipy-1.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~0mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~~ipy'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall \"scipy>=1.14.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da7addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b566696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 112 graphs successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to your folder containing the .pkl files\n",
    "folder_path = \"./graphs\"   # or \"/absolute/path/to/graphs\" if outside your project folder\n",
    "\n",
    "graphs = []\n",
    "\n",
    "# Loop through all .pkl files in the folder\n",
    "for file in glob.glob(os.path.join(folder_path, \"*.pkl\")):\n",
    "    with open(file, 'rb') as f:\n",
    "        graphs.append(pickle.load(f))\n",
    "\n",
    "print(f\"Loaded {len(graphs)} graphs successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcedb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graphs for 3 teams:\n",
      "  Team 1609: 38 graphs\n",
      "  Team 1625: 37 graphs\n",
      "  Team 1612: 37 graphs\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "folder_path = \"./graphs\"\n",
    "\n",
    "# Dictionary: teamID → list of graphs\n",
    "team_graphs = defaultdict(list)\n",
    "\n",
    "# Regex pattern to extract teamID from filenames\n",
    "pattern = re.compile(r'team(\\d+)\\.pkl')\n",
    "\n",
    "for file in glob.glob(os.path.join(folder_path, \"graph_match*_team*.pkl\")):\n",
    "    match = pattern.search(file)\n",
    "    if match:\n",
    "        team_id = int(match.group(1))  # convert to integer if needed\n",
    "        with open(file, 'rb') as f:\n",
    "            graph = pickle.load(f)\n",
    "        team_graphs[team_id].append(graph)\n",
    "\n",
    "print(f\"Loaded graphs for {len(team_graphs)} teams:\")\n",
    "for team_id, graphs in team_graphs.items():\n",
    "    print(f\"  Team {team_id}: {len(graphs)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cfddcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TeamA: 38 graphs\n",
      "TeamB: 37 graphs\n",
      "TeamC: 37 graphs\n"
     ]
    }
   ],
   "source": [
    "# Map numeric team IDs to friendly names\n",
    "team_name_map = {\n",
    "    1609: \"TeamA\",\n",
    "    1625: \"TeamB\",\n",
    "    1612: \"TeamC\"\n",
    "}\n",
    "\n",
    "# Build new dictionary with readable team names\n",
    "team_graphs_dict = {\n",
    "    team_name_map[team_id]: graphs\n",
    "    for team_id, graphs in team_graphs.items()\n",
    "    if team_id in team_name_map\n",
    "}\n",
    "\n",
    "# Quick summary\n",
    "for name, graphs in team_graphs_dict.items():\n",
    "    print(f\"{name}: {len(graphs)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a79539c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#  TEAM-LEVEL GCN AUTOENCODER FOR TACTICAL CLUSTERING\n",
    "# ===========================================\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Prepare each graph as PyG data\n",
    "# -----------------------------\n",
    "def prepare_pyg_data(G, zt=None, add_spatial=True, add_topo=True):\n",
    "    \"\"\"\n",
    "    Converts a zone transition graph into a PyTorch Geometric Data object.\n",
    "    Includes structural, statistical, and spatial node features.\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "\n",
    "    # Optionally precompute graph-level topological measures\n",
    "    if add_topo:\n",
    "        clustering = nx.clustering(G, weight=\"weight\")\n",
    "        pagerank = nx.pagerank(G, weight=\"weight\")\n",
    "\n",
    "    for n in G.nodes():\n",
    "        # --- Structural degrees ---\n",
    "        in_deg = G.in_degree(n, weight=\"weight\")\n",
    "        out_deg = G.out_degree(n, weight=\"weight\")\n",
    "        total_w = in_deg + out_deg\n",
    "\n",
    "        # --- From your existing node attributes ---\n",
    "        event_count = G.nodes[n].get(\"event_count\", 0)\n",
    "        unique_players = G.nodes[n].get(\"unique_players\", 0)\n",
    "\n",
    "        # Role distribution (GK, DF, MD, FW)\n",
    "        role_dist = G.nodes[n].get(\"role_distribution\", [0, 0, 0, 0])\n",
    "\n",
    "        # Encode most_common_event (categorical) → one-hot\n",
    "        event_type = G.nodes[n].get(\"most_common_event\", None)\n",
    "        event_types = [\"pass\", \"shot\", \"dribble\", \"cross\", \"duel\"]  # adjust for your dataset\n",
    "        event_onehot = [1.0 if event_type == et else 0.0 for et in event_types]\n",
    "\n",
    "        # --- Optional spatial coordinates ---\n",
    "        if zt is not None and add_spatial:\n",
    "            x_center, y_center = zt.get_zone_center(n)\n",
    "            x_center, y_center = x_center / 100, y_center / 100\n",
    "        else:\n",
    "            x_center, y_center = 0.0, 0.0\n",
    "\n",
    "        # --- Optional topological measures ---\n",
    "        if add_topo:\n",
    "            cluster_coeff = clustering.get(n, 0.0)\n",
    "            pr = pagerank.get(n, 0.0)\n",
    "        else:\n",
    "            cluster_coeff = pr = 0.0\n",
    "\n",
    "        # --- Combine all features ---\n",
    "        features.append([\n",
    "            in_deg, out_deg, total_w,\n",
    "            event_count, unique_players,\n",
    "            cluster_coeff, pr,\n",
    "            *role_dist,\n",
    "            *event_onehot,\n",
    "            x_center, y_center\n",
    "        ])\n",
    "\n",
    "    X = torch.tensor(np.array(features, dtype=float), dtype=torch.float32)\n",
    "\n",
    "    # Build PyG Data\n",
    "    data = from_networkx(G)\n",
    "    data.x = X\n",
    "\n",
    "    # Edge attributes (weights)\n",
    "    data.edge_attr = torch.tensor(\n",
    "        [G[u][v].get(\"weight\", 1.0) for u, v in G.edges()],\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define the GCN Autoencoder\n",
    "# -----------------------------\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, latent_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight=edge_weight))\n",
    "        z = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        return z\n",
    "\n",
    "\n",
    "class GraphAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GCNEncoder(in_channels, hidden_channels, latent_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encoder(data.x, data.edge_index, data.edge_attr)\n",
    "        # Adjacency reconstruction (inner product)\n",
    "        adj_pred = torch.sigmoid(torch.mm(z, z.t()))\n",
    "        return adj_pred, z\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train on all team graphs jointly\n",
    "# -----------------------------\n",
    "def train_team_autoencoder(team_graphs, zt=None, hidden_dim=16, latent_dim=3,\n",
    "                           epochs=200, lr=0.005, batch_size=1, device=\"cpu\"):\n",
    "\n",
    "    # Prepare PyG data objects\n",
    "    data_list = [prepare_pyg_data(G, zt) for G in team_graphs]\n",
    "    loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Model setup\n",
    "    in_dim = data_list[0].x.shape[1]\n",
    "    model = GraphAutoencoder(in_dim, hidden_dim, latent_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training GCN Autoencoder\"):\n",
    "        total_loss = 0\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            A_pred, _ = model(data)\n",
    "\n",
    "            # Ground-truth adjacency\n",
    "            A_true = torch.zeros_like(A_pred)\n",
    "            for i, (u, v) in enumerate(data.edge_index.t()):\n",
    "                A_true[u, v] = 1.0\n",
    "\n",
    "            loss = F.mse_loss(A_pred, A_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Extract embeddings for each match\n",
    "# -----------------------------\n",
    "def get_team_embeddings(model, team_graphs, zt=None, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    embeddings_per_match = []\n",
    "    with torch.no_grad():\n",
    "        for G in team_graphs:\n",
    "            data = prepare_pyg_data(G, zt).to(device)\n",
    "            _, z = model(data)\n",
    "            # Instead of .numpy(), just keep as list\n",
    "            embeddings_per_match.append(z.cpu().tolist())\n",
    "    return embeddings_per_match\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Example usage\n",
    "# -----------------------------\n",
    "# Suppose you have a dict of team graphs:\n",
    "# team_graphs_dict = {\n",
    "#     \"TeamA\": [G_A1, G_A2, ..., G_A40],\n",
    "#     \"TeamB\": [G_B1, G_B2, ..., G_B40],\n",
    "#     \"TeamC\": [G_C1, G_C2, ..., G_C40],\n",
    "# }\n",
    "\n",
    "# Example run for Team A:\n",
    "# model_A = train_team_autoencoder(team_graphs_dict[\"TeamA\"], zt, epochs=200)\n",
    "# embeddings_A = get_team_embeddings(model_A, team_graphs_dict[\"TeamA\"], zt)\n",
    "#\n",
    "# np.save(\"teamA_zone_embeddings.npy\", embeddings_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ba5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class ZoneTransformer:\n",
    "    \"\"\"Simplified version for zone grid + coordinate mapping.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Grid segmentation (8x5 layout)\n",
    "        self.width_segments = [6, 10, 17, 17, 17, 17, 10, 6]\n",
    "        self.height_segments = [19, 18, 26, 18, 19]\n",
    "\n",
    "        self.n_rows = len(self.height_segments)\n",
    "        self.n_cols = len(self.width_segments)\n",
    "        self.n_zones = self.n_rows * self.n_cols  # 8 x 5\n",
    "        self.outside_zone_id = self.n_zones\n",
    "\n",
    "        self.width_boundaries = np.cumsum([0] + self.width_segments)\n",
    "        self.height_boundaries = np.cumsum([0] + self.height_segments)\n",
    "        self.zone_names = self._create_zone_names()\n",
    "\n",
    "    def _create_zone_names(self):\n",
    "        row_names = [\"RIGHT_WING\", \"RIGHT_HALF\", \"CENTER\", \"LEFT_HALF\", \"LEFT_WING\"]\n",
    "        col_names = [\n",
    "            \"DEF_BOX\",\n",
    "            \"DEF_PENALTY\",\n",
    "            \"DEF_THIRD_DEEP\",\n",
    "            \"DEF_THIRD\",\n",
    "            \"MID_THIRD_DEF\",\n",
    "            \"MID_THIRD_ATT\",\n",
    "            \"ATT_THIRD\",\n",
    "            \"ATT_PENALTY\",\n",
    "        ]\n",
    "        names = {}\n",
    "        for col in range(self.n_cols):\n",
    "            for row in range(self.n_rows):\n",
    "                zid = self.rowcol_to_id(row, col)\n",
    "                names[zid] = f\"{row_names[row]}_{col_names[col]}\"\n",
    "        names[self.outside_zone_id] = \"OUTSIDE\"\n",
    "        return names\n",
    "\n",
    "    def rowcol_to_id(self, row, col):\n",
    "        if row < 0 or row >= self.n_rows or col < 0 or col >= self.n_cols:\n",
    "            return self.outside_zone_id\n",
    "        return col * self.n_rows + (self.n_rows - row - 1)\n",
    "\n",
    "    def id_to_rowcol(self, zid):\n",
    "        if zid == self.outside_zone_id:\n",
    "            return (-1, -1)\n",
    "        row = self.n_rows - (zid % self.n_rows) - 1\n",
    "        col = zid // self.n_rows\n",
    "        return (row, col)\n",
    "\n",
    "    def get_zone_bounds(self, zid):\n",
    "        if zid == self.outside_zone_id:\n",
    "            return (100.0, 100.0, 100.0, 100.0)\n",
    "        row, col = self.id_to_rowcol(zid)\n",
    "        x_min = self.width_boundaries[col]\n",
    "        x_max = self.width_boundaries[col + 1]\n",
    "        y_min = self.height_boundaries[row]\n",
    "        y_max = self.height_boundaries[row + 1]\n",
    "        return (x_min, x_max, y_min, y_max)\n",
    "\n",
    "    def get_zone_center(self, zid):\n",
    "        if zid == self.outside_zone_id:\n",
    "            return (100.0, 100.0)\n",
    "        x_min, x_max, y_min, y_max = self.get_zone_bounds(zid)\n",
    "        return ((x_min + x_max) / 2, (y_min + y_max) / 2)\n",
    "\n",
    "    def get_zone_name(self, zid):\n",
    "        return self.zone_names.get(zid, f\"ZONE_{zid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ec5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zt = ZoneTransformer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b85c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 2.2.6\n",
      "SciPy: 1.15.3\n",
      "PyTorch: 2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy, torch, scipy\n",
    "print(\"NumPy:\", numpy.__version__)\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"PyTorch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ede1b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\utils\\convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  data_dict[key] = torch.as_tensor(value)\n",
      "Training GCN Autoencoder:  10%|█         | 20/200 [00:16<02:17,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 9.9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  20%|██        | 40/200 [00:31<02:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Loss: 9.3492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  30%|███       | 60/200 [00:47<01:49,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Loss: 9.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  40%|████      | 80/200 [01:01<01:27,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Loss: 8.7416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  50%|█████     | 100/200 [01:16<01:13,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Loss: 8.6576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  60%|██████    | 120/200 [01:31<00:59,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Loss: 8.7721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  70%|███████   | 140/200 [01:46<00:44,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Loss: 8.6518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  80%|████████  | 160/200 [02:00<00:29,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Loss: 8.6536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  90%|█████████ | 180/200 [02:15<00:15,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Loss: 8.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder: 100%|██████████| 200/200 [02:30<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Loss: 8.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GCN Autoencoder:  10%|█         | 20/200 [00:14<02:14,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 9.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  20%|██        | 40/200 [00:29<01:56,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Loss: 8.8705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  30%|███       | 60/200 [00:45<02:02,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Loss: 8.8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  40%|████      | 80/200 [01:00<01:28,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Loss: 8.8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  50%|█████     | 100/200 [01:15<01:21,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Loss: 9.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  60%|██████    | 120/200 [01:33<01:19,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Loss: 8.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  70%|███████   | 140/200 [01:51<00:49,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Loss: 8.5111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  80%|████████  | 160/200 [02:06<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Loss: 8.4710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  90%|█████████ | 180/200 [02:21<00:15,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Loss: 8.4306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder: 100%|██████████| 200/200 [02:37<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Loss: 8.4088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GCN Autoencoder:  10%|█         | 20/200 [00:14<02:14,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 9.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  20%|██        | 40/200 [00:29<01:59,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Loss: 8.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  30%|███       | 60/200 [00:44<01:44,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Loss: 8.7096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  40%|████      | 80/200 [00:59<01:29,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Loss: 8.6415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  50%|█████     | 100/200 [01:16<01:33,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Loss: 8.6463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  60%|██████    | 120/200 [01:33<01:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Loss: 8.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  70%|███████   | 140/200 [01:49<00:45,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Loss: 8.6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  80%|████████  | 160/200 [02:07<00:30,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Loss: 8.5121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  90%|█████████ | 180/200 [02:23<00:14,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Loss: 8.6620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder: 100%|██████████| 200/200 [02:38<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Loss: 8.4323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Models training\n",
    "\n",
    "model_A = train_team_autoencoder(team_graphs_dict[\"TeamA\"], zt, epochs=200)\n",
    "model_B = train_team_autoencoder(team_graphs_dict[\"TeamB\"], zt, epochs=200)\n",
    "model_C = train_team_autoencoder(team_graphs_dict[\"TeamC\"], zt, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73652273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering (but only works with entirely with PyTorch because met with problem with NumPy, can also use NumPy directly)\n",
    "\n",
    "import torch\n",
    "\n",
    "def kmeans_torch(X, n_clusters=3, n_iters=100, verbose=False):\n",
    "    \"\"\"\n",
    "    Simple KMeans clustering in PyTorch\n",
    "    X: tensor of shape (n_samples, n_features)\n",
    "    Returns: cluster assignments, centroids\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Initialize centroids randomly from data points\n",
    "    indices = torch.randperm(n_samples)[:n_clusters]\n",
    "    centroids = X[indices]\n",
    "\n",
    "    for i in range(n_iters):\n",
    "        # Compute distances (squared Euclidean)\n",
    "        dists = torch.cdist(X, centroids, p=2)  # (n_samples, n_clusters)\n",
    "        # Assign clusters\n",
    "        cluster_ids = torch.argmin(dists, dim=1)\n",
    "        # Update centroids\n",
    "        new_centroids = torch.stack([\n",
    "            X[cluster_ids == k].mean(dim=0) if (cluster_ids == k).sum() > 0 else centroids[k]\n",
    "            for k in range(n_clusters)\n",
    "        ])\n",
    "        # Check for convergence\n",
    "        if torch.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "        if verbose:\n",
    "            print(f\"Iteration {i+1} done\")\n",
    "    return cluster_ids, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae36cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get embeddings from trained autoencoders\n",
    "emb_A = get_team_embeddings(model_A, team_graphs_dict[\"TeamA\"], zt)\n",
    "emb_B = get_team_embeddings(model_B, team_graphs_dict[\"TeamB\"], zt)\n",
    "emb_C = get_team_embeddings(model_C, team_graphs_dict[\"TeamC\"], zt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7acc9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your embeddings to a tensor\n",
    "emb_A_tensor = torch.tensor([item for match in emb_A for item in match], dtype=torch.float32)\n",
    "emb_B_tensor = torch.tensor([item for match in emb_B for item in match], dtype=torch.float32)\n",
    "emb_C_tensor = torch.tensor([item for match in emb_C for item in match], dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa951012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cluster\n",
    "clusters_A, centroids_A = kmeans_torch(emb_A_tensor, n_clusters=3)\n",
    "clusters_B, centroids_B = kmeans_torch(emb_B_tensor, n_clusters=3)\n",
    "clusters_C, centroids_C = kmeans_torch(emb_C_tensor, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b393df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display  # optional, only for notebook\n",
    "\n",
    "# -------------------------\n",
    "# 1) PyTorch KMeans\n",
    "# -------------------------\n",
    "def kmeans_torch(X, n_clusters=4, n_iters=200, tol=1e-4, verbose=False, device=\"cpu\"):\n",
    "    X = X.to(device)\n",
    "    n_samples, n_features = X.shape\n",
    "    rand_idx = torch.randperm(n_samples, device=device)[:n_clusters]\n",
    "    centroids = X[rand_idx].clone()\n",
    "\n",
    "    for it in range(n_iters):\n",
    "        dists = torch.cdist(X, centroids, p=2)\n",
    "        labels = torch.argmin(dists, dim=1)\n",
    "\n",
    "        new_centroids = torch.zeros_like(centroids)\n",
    "        converged = True\n",
    "        for k in range(n_clusters):\n",
    "            mask = (labels == k)\n",
    "            if mask.sum() == 0:\n",
    "                new_centroids[k] = centroids[k]\n",
    "            else:\n",
    "                new_centroids[k] = X[mask].mean(dim=0)\n",
    "            if not torch.allclose(new_centroids[k], centroids[k], atol=tol):\n",
    "                converged = False\n",
    "        centroids = new_centroids\n",
    "        if verbose and (it % 20 == 0 or converged):\n",
    "            print(f\"KMeans iter {it}, converged={converged}\")\n",
    "        if converged:\n",
    "            break\n",
    "    return labels.cpu(), centroids.cpu()\n",
    "\n",
    "# -------------------------\n",
    "# 2) Pillow visualization\n",
    "# -------------------------\n",
    "DEFAULT_COLORS = [\n",
    "    (31, 119, 180), (255, 127, 14), (44, 160, 44), (214, 39, 40),\n",
    "    (148, 103, 189), (140, 86, 75), (227, 119, 194), (127, 127, 127)\n",
    "]\n",
    "\n",
    "def draw_pitch_zone_clusters(zt, clusters_per_zone, out_path, figsize=(1000, 640), title=None):\n",
    "    W, H = figsize\n",
    "    im = Image.new(\"RGB\", (W, H), (26,26,26))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    margin = 30\n",
    "    def to_px(x, y):\n",
    "        px = margin + (x / 100.0) * (W - 2 * margin)\n",
    "        py = margin + ((100 - y) / 100.0) * (H - 2 * margin)\n",
    "        return px, py\n",
    "\n",
    "    # pitch border\n",
    "    draw.rectangle([to_px(0,100), to_px(100,0)], outline=(255,255,255), width=3)\n",
    "\n",
    "    for zid, cid in enumerate(clusters_per_zone):\n",
    "        x_min, x_max, y_min, y_max = zt.get_zone_bounds(zid)\n",
    "        tl = to_px(x_min, y_max)\n",
    "        br = to_px(x_max, y_min)\n",
    "        color = DEFAULT_COLORS[cid % len(DEFAULT_COLORS)]\n",
    "        draw.rectangle([tl, br], fill=color, outline=(255,255,255))\n",
    "        cx, cy = zt.get_zone_center(zid)\n",
    "        px, py = to_px(cx, cy)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", size=18)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((px-10, py-8), str(zid), fill=(255,255,255), font=font)\n",
    "\n",
    "    if title:\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", size=22)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((W//2 - 200, 10), title, fill=(255,255,255), font=font)\n",
    "\n",
    "    im.save(out_path)\n",
    "    return out_path\n",
    "\n",
    "# -------------------------\n",
    "# 3) Cluster + draw per team\n",
    "# -------------------------\n",
    "def cluster_and_draw_team_majority(embeddings, zt, team_name=\"Team\", n_clusters=4, verbose=False):\n",
    "    \"\"\"\n",
    "    embeddings: list-of-matches, each match = list (n_zones x feature_dim)\n",
    "    Produces: saved PNG for team-level majority clusters only.\n",
    "    \"\"\"\n",
    "    all_zone_labels_per_match = []\n",
    "\n",
    "    # Cluster per match, but don't draw\n",
    "    for match_emb in embeddings:\n",
    "        X = torch.tensor(match_emb, dtype=torch.float32)\n",
    "        labels, _ = kmeans_torch(X, n_clusters=n_clusters, verbose=verbose)\n",
    "        all_zone_labels_per_match.append(labels.tolist())\n",
    "\n",
    "    # Compute per-zone majority vote across matches\n",
    "    max_zones = max(len(m) for m in embeddings)\n",
    "    majority_zone_labels = []\n",
    "    for zid in range(max_zones):\n",
    "        votes = [match_labels[zid] for match_labels in all_zone_labels_per_match if zid < len(match_labels)]\n",
    "        if votes:\n",
    "            vals, counts = torch.unique(torch.tensor(votes), return_counts=True)\n",
    "            majority = vals[torch.argmax(counts)].item()\n",
    "        else:\n",
    "            majority = 0\n",
    "        majority_zone_labels.append(majority)\n",
    "\n",
    "    # Draw team-level cluster\n",
    "    team_out_path = f\"{team_name}_team_clusters.png\"\n",
    "    draw_pitch_zone_clusters(zt, majority_zone_labels, team_out_path, title=f\"{team_name} Majority Clusters\")\n",
    "    if verbose:\n",
    "        print(f\"Saved team-level clusters: {team_out_path}\")\n",
    "\n",
    "    return majority_zone_labels, team_out_path\n",
    "# -------------------------\n",
    "# 4) Example usage\n",
    "# -------------------------\n",
    "# emb_A, emb_B, emb_C = your previously obtained embeddings\n",
    "# zt = ZoneTransformer()  # must be defined\n",
    "\n",
    "# cluster & draw\n",
    "# majority_A, per_match_A, path_A = cluster_and_draw_team(emb_A, zt, team_name=\"TeamA\", n_clusters=4, verbose=True)\n",
    "# majority_B, per_match_B, path_B = cluster_and_draw_team(emb_B, zt, team_name=\"TeamB\", n_clusters=4, verbose=True)\n",
    "# majority_C, per_match_C, path_C = cluster_and_draw_team(emb_C, zt, team_name=\"TeamC\", n_clusters=4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d7b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 10, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 8, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved team-level clusters: TeamA_team_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 8, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 8, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved team-level clusters: TeamB_team_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved team-level clusters: TeamC_team_clusters.png\n"
     ]
    }
   ],
   "source": [
    "zt = ZoneTransformer()  # must be defined\n",
    "majority_A, path_A = cluster_and_draw_team_majority(emb_A, zt, team_name=\"TeamA\", n_clusters=4, verbose=True)\n",
    "majority_B, path_B = cluster_and_draw_team_majority(emb_B, zt, team_name=\"TeamB\", n_clusters=4, verbose=True)\n",
    "majority_C, path_C = cluster_and_draw_team_majority(emb_C, zt, team_name=\"TeamC\", n_clusters=4, verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
