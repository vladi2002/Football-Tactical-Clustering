{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153353c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.6\n",
      "Uninstalling numpy-2.2.6:\n",
      "  Successfully uninstalled numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~-mpy.libs'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~~mpy'.\n",
      "You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall numpy -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "939e3f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy>=2.0.0\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\kangkanglbk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.2.6 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy>=2.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52b0db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.6\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b566696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 112 graphs successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to your folder containing the .pkl files\n",
    "folder_path = \"./graphs\"   # or \"/absolute/path/to/graphs\" if outside your project folder\n",
    "\n",
    "graphs = []\n",
    "\n",
    "# Loop through all .pkl files in the folder\n",
    "for file in glob.glob(os.path.join(folder_path, \"*.pkl\")):\n",
    "    with open(file, 'rb') as f:\n",
    "        graphs.append(pickle.load(f))\n",
    "\n",
    "print(f\"Loaded {len(graphs)} graphs successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcedb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graphs for 3 teams:\n",
      "  Team 1609: 38 graphs\n",
      "  Team 1625: 37 graphs\n",
      "  Team 1612: 37 graphs\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "folder_path = \"./graphs\"\n",
    "\n",
    "# Dictionary: teamID → list of graphs\n",
    "team_graphs = defaultdict(list)\n",
    "\n",
    "# Regex pattern to extract teamID from filenames\n",
    "pattern = re.compile(r'team(\\d+)\\.pkl')\n",
    "\n",
    "for file in glob.glob(os.path.join(folder_path, \"graph_match*_team*.pkl\")):\n",
    "    match = pattern.search(file)\n",
    "    if match:\n",
    "        team_id = int(match.group(1))  # convert to integer if needed\n",
    "        with open(file, 'rb') as f:\n",
    "            graph = pickle.load(f)\n",
    "        team_graphs[team_id].append(graph)\n",
    "\n",
    "print(f\"Loaded graphs for {len(team_graphs)} teams:\")\n",
    "for team_id, graphs in team_graphs.items():\n",
    "    print(f\"  Team {team_id}: {len(graphs)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cfddcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TeamA: 38 graphs\n",
      "TeamB: 37 graphs\n",
      "TeamC: 37 graphs\n"
     ]
    }
   ],
   "source": [
    "# Map numeric team IDs to friendly names\n",
    "team_name_map = {\n",
    "    1609: \"TeamA\",\n",
    "    1625: \"TeamB\",\n",
    "    1612: \"TeamC\"\n",
    "}\n",
    "\n",
    "# Build new dictionary with readable team names\n",
    "team_graphs_dict = {\n",
    "    team_name_map[team_id]: graphs\n",
    "    for team_id, graphs in team_graphs.items()\n",
    "    if team_id in team_name_map\n",
    "}\n",
    "\n",
    "# Quick summary\n",
    "for name, graphs in team_graphs_dict.items():\n",
    "    print(f\"{name}: {len(graphs)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79539c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Kangkanglbk\\AppData\\Local\\Temp\\ipykernel_28464\\1959953033.py\", line 6, in <module>\n",
      "    from torch_geometric.nn import GCNConv\n",
      "  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\__init__.py\", line 22, in <module>\n",
      "    import torch_geometric.datasets\n",
      "  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\datasets\\__init__.py\", line 18, in <module>\n",
      "    from .qm9 import QM9\n",
      "  File \"c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\datasets\\qm9.py\", line 22, in <module>\n",
      "    conversion = torch.tensor([\n",
      "c:\\Users\\Kangkanglbk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\datasets\\qm9.py:22: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  conversion = torch.tensor([\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "#  TEAM-LEVEL GCN AUTOENCODER FOR TACTICAL CLUSTERING\n",
    "# ===========================================\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Prepare each graph as PyG data\n",
    "# -----------------------------\n",
    "def prepare_pyg_data(G, zt=None, add_spatial=True):\n",
    "    \"\"\"\n",
    "    Converts a zone transition graph into a PyTorch Geometric Data object.\n",
    "    Includes node features + edge weights.\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "    for n in G.nodes():\n",
    "        # Structural features\n",
    "        in_deg = G.in_degree(n, weight='weight')\n",
    "        out_deg = G.out_degree(n, weight='weight')\n",
    "        total_w = in_deg + out_deg\n",
    "\n",
    "        # Role distribution if available (GK, DF, MD, FW)\n",
    "        role_dist = G.nodes[n].get(\"role_distribution\", [0, 0, 0, 0])\n",
    "\n",
    "        # Optional spatial feature\n",
    "        if zt is not None and add_spatial:\n",
    "            x_center, y_center = zt.get_zone_center(n)\n",
    "            x_center, y_center = x_center / 100, y_center / 100\n",
    "        else:\n",
    "            x_center, y_center = 0.0, 0.0\n",
    "\n",
    "        features.append([\n",
    "            in_deg, out_deg, total_w,\n",
    "            *role_dist,\n",
    "            x_center, y_center\n",
    "        ])\n",
    "\n",
    "    X = torch.tensor(np.array(features, dtype=float), dtype=torch.float32)\n",
    "\n",
    "    data = from_networkx(G)\n",
    "    data.x = X\n",
    "\n",
    "    # Add edge weights as attributes\n",
    "    edge_weights = [G[u][v].get(\"weight\", 1.0) for u, v in G.edges()]\n",
    "    data.edge_attr = torch.tensor(edge_weights, dtype=torch.float32)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define the GCN Autoencoder\n",
    "# -----------------------------\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, latent_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight=edge_weight))\n",
    "        z = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        return z\n",
    "\n",
    "\n",
    "class GraphAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GCNEncoder(in_channels, hidden_channels, latent_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encoder(data.x, data.edge_index, data.edge_attr)\n",
    "        # Adjacency reconstruction (inner product)\n",
    "        adj_pred = torch.sigmoid(torch.mm(z, z.t()))\n",
    "        return adj_pred, z\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train on all team graphs jointly\n",
    "# -----------------------------\n",
    "def train_team_autoencoder(team_graphs, zt=None, hidden_dim=16, latent_dim=3,\n",
    "                           epochs=200, lr=0.005, batch_size=1, device=\"cpu\"):\n",
    "\n",
    "    # Prepare PyG data objects\n",
    "    data_list = [prepare_pyg_data(G, zt) for G in team_graphs]\n",
    "    loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Model setup\n",
    "    in_dim = data_list[0].x.shape[1]\n",
    "    model = GraphAutoencoder(in_dim, hidden_dim, latent_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training GCN Autoencoder\"):\n",
    "        total_loss = 0\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            A_pred, _ = model(data)\n",
    "\n",
    "            # Ground-truth adjacency\n",
    "            A_true = torch.zeros_like(A_pred)\n",
    "            for i, (u, v) in enumerate(data.edge_index.t()):\n",
    "                A_true[u, v] = 1.0\n",
    "\n",
    "            loss = F.mse_loss(A_pred, A_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Extract embeddings for each match\n",
    "# -----------------------------\n",
    "def get_team_embeddings(model, team_graphs, zt=None, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    embeddings_per_match = []\n",
    "    with torch.no_grad():\n",
    "        for G in team_graphs:\n",
    "            data = prepare_pyg_data(G, zt).to(device)\n",
    "            _, z = model(data)\n",
    "            # Instead of .numpy(), just keep as list\n",
    "            embeddings_per_match.append(z.cpu().tolist())\n",
    "    return embeddings_per_match\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Example usage\n",
    "# -----------------------------\n",
    "# Suppose you have a dict of team graphs:\n",
    "# team_graphs_dict = {\n",
    "#     \"TeamA\": [G_A1, G_A2, ..., G_A40],\n",
    "#     \"TeamB\": [G_B1, G_B2, ..., G_B40],\n",
    "#     \"TeamC\": [G_C1, G_C2, ..., G_C40],\n",
    "# }\n",
    "\n",
    "# Example run for Team A:\n",
    "# model_A = train_team_autoencoder(team_graphs_dict[\"TeamA\"], zt, epochs=200)\n",
    "# embeddings_A = get_team_embeddings(model_A, team_graphs_dict[\"TeamA\"], zt)\n",
    "#\n",
    "# np.save(\"teamA_zone_embeddings.npy\", embeddings_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ba5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class ZoneTransformer:\n",
    "    \"\"\"Simplified version for zone grid + coordinate mapping.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Grid segmentation (8x5 layout)\n",
    "        self.width_segments = [6, 10, 17, 17, 17, 17, 10, 6]\n",
    "        self.height_segments = [19, 18, 26, 18, 19]\n",
    "\n",
    "        self.n_rows = len(self.height_segments)\n",
    "        self.n_cols = len(self.width_segments)\n",
    "        self.n_zones = self.n_rows * self.n_cols  # 8 x 5\n",
    "        self.outside_zone_id = self.n_zones\n",
    "\n",
    "        self.width_boundaries = np.cumsum([0] + self.width_segments)\n",
    "        self.height_boundaries = np.cumsum([0] + self.height_segments)\n",
    "        self.zone_names = self._create_zone_names()\n",
    "\n",
    "    def _create_zone_names(self):\n",
    "        row_names = [\"RIGHT_WING\", \"RIGHT_HALF\", \"CENTER\", \"LEFT_HALF\", \"LEFT_WING\"]\n",
    "        col_names = [\n",
    "            \"DEF_BOX\",\n",
    "            \"DEF_PENALTY\",\n",
    "            \"DEF_THIRD_DEEP\",\n",
    "            \"DEF_THIRD\",\n",
    "            \"MID_THIRD_DEF\",\n",
    "            \"MID_THIRD_ATT\",\n",
    "            \"ATT_THIRD\",\n",
    "            \"ATT_PENALTY\",\n",
    "        ]\n",
    "        names = {}\n",
    "        for col in range(self.n_cols):\n",
    "            for row in range(self.n_rows):\n",
    "                zid = self.rowcol_to_id(row, col)\n",
    "                names[zid] = f\"{row_names[row]}_{col_names[col]}\"\n",
    "        names[self.outside_zone_id] = \"OUTSIDE\"\n",
    "        return names\n",
    "\n",
    "    def rowcol_to_id(self, row, col):\n",
    "        if row < 0 or row >= self.n_rows or col < 0 or col >= self.n_cols:\n",
    "            return self.outside_zone_id\n",
    "        return col * self.n_rows + (self.n_rows - row - 1)\n",
    "\n",
    "    def id_to_rowcol(self, zid):\n",
    "        if zid == self.outside_zone_id:\n",
    "            return (-1, -1)\n",
    "        row = self.n_rows - (zid % self.n_rows) - 1\n",
    "        col = zid // self.n_rows\n",
    "        return (row, col)\n",
    "\n",
    "    def get_zone_bounds(self, zid):\n",
    "        if zid == self.outside_zone_id:\n",
    "            return (100.0, 100.0, 100.0, 100.0)\n",
    "        row, col = self.id_to_rowcol(zid)\n",
    "        x_min = self.width_boundaries[col]\n",
    "        x_max = self.width_boundaries[col + 1]\n",
    "        y_min = self.height_boundaries[row]\n",
    "        y_max = self.height_boundaries[row + 1]\n",
    "        return (x_min, x_max, y_min, y_max)\n",
    "\n",
    "    def get_zone_center(self, zid):\n",
    "        if zid == self.outside_zone_id:\n",
    "            return (100.0, 100.0)\n",
    "        x_min, x_max, y_min, y_max = self.get_zone_bounds(zid)\n",
    "        return ((x_min + x_max) / 2, (y_min + y_max) / 2)\n",
    "\n",
    "    def get_zone_name(self, zid):\n",
    "        return self.zone_names.get(zid, f\"ZONE_{zid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ec5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zt = ZoneTransformer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede1b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  10%|█         | 20/200 [00:14<02:06,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 9.6965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  20%|██        | 40/200 [00:28<01:54,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Loss: 9.4895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  30%|███       | 60/200 [00:42<01:38,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Loss: 8.9944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  40%|████      | 80/200 [00:56<01:25,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Loss: 8.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  50%|█████     | 100/200 [01:11<01:12,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Loss: 8.7235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  60%|██████    | 120/200 [01:25<00:55,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Loss: 8.6824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  70%|███████   | 140/200 [01:39<00:46,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Loss: 8.6417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  80%|████████  | 160/200 [01:55<00:28,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Loss: 8.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  90%|█████████ | 180/200 [02:09<00:15,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Loss: 8.6030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder: 100%|██████████| 200/200 [02:24<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Loss: 8.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GCN Autoencoder:  10%|█         | 20/200 [00:13<02:09,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 9.3095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  20%|██        | 40/200 [00:29<02:02,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Loss: 8.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  30%|███       | 60/200 [00:45<02:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Loss: 9.2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  40%|████      | 80/200 [01:00<01:41,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Loss: 9.2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  50%|█████     | 100/200 [01:17<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Loss: 8.7591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  60%|██████    | 120/200 [01:32<00:58,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Loss: 8.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  70%|███████   | 140/200 [01:49<00:53,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Loss: 8.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  80%|████████  | 160/200 [02:06<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Loss: 8.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  90%|█████████ | 180/200 [02:21<00:15,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Loss: 8.4789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder: 100%|██████████| 200/200 [02:35<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Loss: 8.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GCN Autoencoder:  10%|█         | 20/200 [00:14<02:07,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 10.2664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  20%|██        | 40/200 [00:29<02:02,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Loss: 9.2795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  30%|███       | 60/200 [00:43<01:40,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Loss: 9.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  40%|████      | 80/200 [00:58<01:26,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Loss: 8.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  50%|█████     | 100/200 [01:12<01:08,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Loss: 8.7837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  60%|██████    | 120/200 [01:26<00:57,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Loss: 8.7635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  70%|███████   | 140/200 [01:43<00:52,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Loss: 8.8263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  80%|████████  | 160/200 [01:59<00:27,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Loss: 8.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder:  90%|█████████ | 180/200 [02:12<00:14,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Loss: 8.6492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GCN Autoencoder: 100%|██████████| 200/200 [02:27<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Loss: 8.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Models training\n",
    "\n",
    "model_A = train_team_autoencoder(team_graphs_dict[\"TeamA\"], zt, epochs=200)\n",
    "model_B = train_team_autoencoder(team_graphs_dict[\"TeamB\"], zt, epochs=200)\n",
    "model_C = train_team_autoencoder(team_graphs_dict[\"TeamC\"], zt, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73652273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering (but only works with entirely with PyTorch because met with problem with NumPy, can also use NumPy directly)\n",
    "\n",
    "import torch\n",
    "\n",
    "def kmeans_torch(X, n_clusters=3, n_iters=100, verbose=False):\n",
    "    \"\"\"\n",
    "    Simple KMeans clustering in PyTorch\n",
    "    X: tensor of shape (n_samples, n_features)\n",
    "    Returns: cluster assignments, centroids\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Initialize centroids randomly from data points\n",
    "    indices = torch.randperm(n_samples)[:n_clusters]\n",
    "    centroids = X[indices]\n",
    "\n",
    "    for i in range(n_iters):\n",
    "        # Compute distances (squared Euclidean)\n",
    "        dists = torch.cdist(X, centroids, p=2)  # (n_samples, n_clusters)\n",
    "        # Assign clusters\n",
    "        cluster_ids = torch.argmin(dists, dim=1)\n",
    "        # Update centroids\n",
    "        new_centroids = torch.stack([\n",
    "            X[cluster_ids == k].mean(dim=0) if (cluster_ids == k).sum() > 0 else centroids[k]\n",
    "            for k in range(n_clusters)\n",
    "        ])\n",
    "        # Check for convergence\n",
    "        if torch.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "        if verbose:\n",
    "            print(f\"Iteration {i+1} done\")\n",
    "    return cluster_ids, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae36cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get embeddings from trained autoencoders\n",
    "emb_A = get_team_embeddings(model_A, team_graphs_dict[\"TeamA\"], zt)\n",
    "emb_B = get_team_embeddings(model_B, team_graphs_dict[\"TeamB\"], zt)\n",
    "emb_C = get_team_embeddings(model_C, team_graphs_dict[\"TeamC\"], zt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acc9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your embeddings to a tensor\n",
    "emb_A_tensor = torch.tensor([item for match in emb_A for item in match], dtype=torch.float32)\n",
    "emb_B_tensor = torch.tensor([item for match in emb_B for item in match], dtype=torch.float32)\n",
    "emb_C_tensor = torch.tensor([item for match in emb_C for item in match], dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa951012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cluster\n",
    "clusters_A, centroids_A = kmeans_torch(emb_A_tensor, n_clusters=3)\n",
    "clusters_B, centroids_B = kmeans_torch(emb_B_tensor, n_clusters=3)\n",
    "clusters_C, centroids_C = kmeans_torch(emb_C_tensor, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b393df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display  # optional, only for notebook\n",
    "\n",
    "# -------------------------\n",
    "# 1) PyTorch KMeans\n",
    "# -------------------------\n",
    "def kmeans_torch(X, n_clusters=4, n_iters=200, tol=1e-4, verbose=False, device=\"cpu\"):\n",
    "    X = X.to(device)\n",
    "    n_samples, n_features = X.shape\n",
    "    rand_idx = torch.randperm(n_samples, device=device)[:n_clusters]\n",
    "    centroids = X[rand_idx].clone()\n",
    "\n",
    "    for it in range(n_iters):\n",
    "        dists = torch.cdist(X, centroids, p=2)\n",
    "        labels = torch.argmin(dists, dim=1)\n",
    "\n",
    "        new_centroids = torch.zeros_like(centroids)\n",
    "        converged = True\n",
    "        for k in range(n_clusters):\n",
    "            mask = (labels == k)\n",
    "            if mask.sum() == 0:\n",
    "                new_centroids[k] = centroids[k]\n",
    "            else:\n",
    "                new_centroids[k] = X[mask].mean(dim=0)\n",
    "            if not torch.allclose(new_centroids[k], centroids[k], atol=tol):\n",
    "                converged = False\n",
    "        centroids = new_centroids\n",
    "        if verbose and (it % 20 == 0 or converged):\n",
    "            print(f\"KMeans iter {it}, converged={converged}\")\n",
    "        if converged:\n",
    "            break\n",
    "    return labels.cpu(), centroids.cpu()\n",
    "\n",
    "# -------------------------\n",
    "# 2) Pillow visualization\n",
    "# -------------------------\n",
    "DEFAULT_COLORS = [\n",
    "    (31, 119, 180), (255, 127, 14), (44, 160, 44), (214, 39, 40),\n",
    "    (148, 103, 189), (140, 86, 75), (227, 119, 194), (127, 127, 127)\n",
    "]\n",
    "\n",
    "def draw_pitch_zone_clusters(zt, clusters_per_zone, out_path, figsize=(1000, 640), title=None):\n",
    "    W, H = figsize\n",
    "    im = Image.new(\"RGB\", (W, H), (26,26,26))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    margin = 30\n",
    "    def to_px(x, y):\n",
    "        px = margin + (x / 100.0) * (W - 2 * margin)\n",
    "        py = margin + ((100 - y) / 100.0) * (H - 2 * margin)\n",
    "        return px, py\n",
    "\n",
    "    # pitch border\n",
    "    draw.rectangle([to_px(0,100), to_px(100,0)], outline=(255,255,255), width=3)\n",
    "\n",
    "    for zid, cid in enumerate(clusters_per_zone):\n",
    "        x_min, x_max, y_min, y_max = zt.get_zone_bounds(zid)\n",
    "        tl = to_px(x_min, y_max)\n",
    "        br = to_px(x_max, y_min)\n",
    "        color = DEFAULT_COLORS[cid % len(DEFAULT_COLORS)]\n",
    "        draw.rectangle([tl, br], fill=color, outline=(255,255,255))\n",
    "        cx, cy = zt.get_zone_center(zid)\n",
    "        px, py = to_px(cx, cy)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", size=18)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((px-10, py-8), str(zid), fill=(255,255,255), font=font)\n",
    "\n",
    "    if title:\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", size=22)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((W//2 - 200, 10), title, fill=(255,255,255), font=font)\n",
    "\n",
    "    im.save(out_path)\n",
    "    return out_path\n",
    "\n",
    "# -------------------------\n",
    "# 3) Cluster + draw per team\n",
    "# -------------------------\n",
    "def cluster_and_draw_team(embeddings, zt, team_name=\"Team\", n_clusters=4, verbose=False):\n",
    "    \"\"\"\n",
    "    embeddings: list-of-matches, each match = list (n_zones x feature_dim)\n",
    "    Produces: saved PNG per match and returns majority-vote cluster per zone\n",
    "    \"\"\"\n",
    "    n_matches = len(embeddings)\n",
    "    all_zone_labels_per_match = []\n",
    "\n",
    "    for i, match_emb in enumerate(embeddings):\n",
    "        X = torch.tensor(match_emb, dtype=torch.float32)\n",
    "        labels, _ = kmeans_torch(X, n_clusters=n_clusters, verbose=verbose)\n",
    "        zone_labels = labels.tolist()\n",
    "        all_zone_labels_per_match.append(zone_labels)\n",
    "\n",
    "        # draw per match\n",
    "        out_path = f\"{team_name}_match{i+1}_clusters.png\"\n",
    "        draw_pitch_zone_clusters(zt, zone_labels, out_path, title=f\"{team_name} Match {i+1}\")\n",
    "        if verbose:\n",
    "            print(f\"Saved {out_path}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Compute per-zone majority vote across matches\n",
    "    # -------------------------\n",
    "    max_zones = max(len(m) for m in embeddings)\n",
    "    majority_zone_labels = []\n",
    "    for zid in range(max_zones):\n",
    "        votes = []\n",
    "        for match_labels in all_zone_labels_per_match:\n",
    "            if zid < len(match_labels):\n",
    "                votes.append(match_labels[zid])\n",
    "        if votes:\n",
    "            # majority vote\n",
    "            vals, counts = torch.unique(torch.tensor(votes), return_counts=True)\n",
    "            majority = vals[torch.argmax(counts)].item()\n",
    "        else:\n",
    "            majority = 0\n",
    "        majority_zone_labels.append(majority)\n",
    "\n",
    "    # draw team-level cluster\n",
    "    team_out_path = f\"{team_name}_team_clusters.png\"\n",
    "    draw_pitch_zone_clusters(zt, majority_zone_labels, team_out_path, title=f\"{team_name} Majority Clusters\")\n",
    "    if verbose:\n",
    "        print(f\"Saved team-level clusters: {team_out_path}\")\n",
    "\n",
    "    return majority_zone_labels, all_zone_labels_per_match, team_out_path\n",
    "\n",
    "# -------------------------\n",
    "# 4) Example usage\n",
    "# -------------------------\n",
    "# emb_A, emb_B, emb_C = your previously obtained embeddings\n",
    "# zt = ZoneTransformer()  # must be defined\n",
    "\n",
    "# cluster & draw\n",
    "# majority_A, per_match_A, path_A = cluster_and_draw_team(emb_A, zt, team_name=\"TeamA\", n_clusters=4, verbose=True)\n",
    "# majority_B, per_match_B, path_B = cluster_and_draw_team(emb_B, zt, team_name=\"TeamB\", n_clusters=4, verbose=True)\n",
    "# majority_C, per_match_C, path_C = cluster_and_draw_team(emb_C, zt, team_name=\"TeamC\", n_clusters=4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d7b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamA_match1_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match2_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 8, converged=True\n",
      "Saved TeamA_match3_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamA_match4_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "Saved TeamA_match5_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 10, converged=True\n",
      "Saved TeamA_match6_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match7_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamA_match8_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 8, converged=True\n",
      "Saved TeamA_match9_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamA_match10_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "Saved TeamA_match11_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match12_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamA_match13_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 8, converged=True\n",
      "Saved TeamA_match14_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "Saved TeamA_match15_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "Saved TeamA_match16_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamA_match17_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match18_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "Saved TeamA_match19_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamA_match20_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 9, converged=True\n",
      "Saved TeamA_match21_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match22_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamA_match23_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "Saved TeamA_match24_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match25_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match26_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 8, converged=True\n",
      "Saved TeamA_match27_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamA_match28_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamA_match29_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match30_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamA_match31_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamA_match32_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match33_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamA_match34_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamA_match35_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamA_match36_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamA_match37_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamA_match38_clusters.png\n",
      "Saved team-level clusters: TeamA_team_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match1_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamB_match2_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match3_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match4_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match5_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match6_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "Saved TeamB_match7_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "Saved TeamB_match8_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "Saved TeamB_match9_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 10, converged=True\n",
      "Saved TeamB_match10_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match11_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "Saved TeamB_match12_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match13_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamB_match14_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match15_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match16_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamB_match17_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match18_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match19_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamB_match20_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamB_match21_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match22_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match23_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "Saved TeamB_match24_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 7, converged=True\n",
      "Saved TeamB_match25_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match26_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamB_match27_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamB_match28_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamB_match29_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match30_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match31_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamB_match32_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match33_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 9, converged=True\n",
      "Saved TeamB_match34_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamB_match35_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamB_match36_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamB_match37_clusters.png\n",
      "Saved team-level clusters: TeamB_team_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match1_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match2_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match3_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamC_match4_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match5_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match6_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match7_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamC_match8_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamC_match9_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match10_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamC_match11_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match12_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "Saved TeamC_match13_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match14_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match15_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "Saved TeamC_match16_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamC_match17_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match18_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match19_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match20_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamC_match21_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match22_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match23_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match24_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "Saved TeamC_match25_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match26_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match27_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamC_match28_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match29_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 6, converged=True\n",
      "Saved TeamC_match30_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match31_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 2, converged=True\n",
      "Saved TeamC_match32_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match33_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 4, converged=True\n",
      "Saved TeamC_match34_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 5, converged=True\n",
      "Saved TeamC_match35_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 3, converged=True\n",
      "Saved TeamC_match36_clusters.png\n",
      "KMeans iter 0, converged=False\n",
      "KMeans iter 1, converged=True\n",
      "Saved TeamC_match37_clusters.png\n",
      "Saved team-level clusters: TeamC_team_clusters.png\n"
     ]
    }
   ],
   "source": [
    "zt = ZoneTransformer()  # must be defined\n",
    "majority_A, per_match_A, path_A = cluster_and_draw_team(emb_A, zt, team_name=\"TeamA\", n_clusters=4, verbose=True)\n",
    "majority_B, per_match_B, path_B = cluster_and_draw_team(emb_B, zt, team_name=\"TeamB\", n_clusters=4, verbose=True)\n",
    "majority_C, per_match_C, path_C = cluster_and_draw_team(emb_C, zt, team_name=\"TeamC\", n_clusters=4, verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
